{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350701ec-c5f9-4809-884c-69a5dcf97ceb",
   "metadata": {},
   "source": [
    "# Data Creation from Food101 Database\n",
    "\n",
    "This notebook creates a PyTorch dataset with differnt types of food. PyTorch now incorporates Food101.\n",
    "\n",
    "Three classes: Pizza, Steak, Sushi.\n",
    "\n",
    "The target dataset folder structure is as follows:\n",
    "\n",
    "```\n",
    "pizza_steak_sushi/\n",
    "    train/\n",
    "        pizza/\n",
    "            image01.jpeg\n",
    "            image02.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image04.jpeg\n",
    "            image05.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image07.jpeg\n",
    "            ...\n",
    "    test/\n",
    "        pizza/\n",
    "            image101.jpeg\n",
    "            image102.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image104.jpeg\n",
    "            image105.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image107.jpeg\n",
    "            ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f42bd9-459c-44cb-a0cf-d1b24599ff81",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Get the Food101 dataset from PyTorch.\n",
    "* Food101 in `torchvision.datasets` - https://pytorch.org/vision/stable/generated/torchvision.datasets.Food101.html\n",
    "* Original Food101 dataset - https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6304649-b3d2-4341-8adb-4d0382415d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directory\n",
    "from pathlib import Path\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "# Get training data\n",
    "train_data = datasets.Food101(root=data_dir,\n",
    "                              split=\"train\",\n",
    "                              # transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "# Get testing data\n",
    "test_data = datasets.Food101(root=data_dir,\n",
    "                             split=\"test\",\n",
    "                             # transform=transforms.ToTensor(),\n",
    "                             download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d418e1-9eb9-4cb4-abc0-03c6d8b1a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6ea58-9b35-4321-a27b-eb6bed2afc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d480e9b-9fd6-44fb-9bf6-512421db6900",
   "metadata": {},
   "source": [
    "## Extract the Subset of Target Classes\n",
    "\n",
    "A list of the different target image classes (`pizza`, `steak`, `sushi`) filenames will be created and copied to separate folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb70f3d-54ce-4fcb-beb1-db57c31f61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 100% of training images\n",
    "import random\n",
    "\n",
    "# Setup data paths\n",
    "data_path = data_dir / \"food-101\" / \"images\"\n",
    "target_classes = class_names #[\"pizza\", \"steak\", \"sushi\"]\n",
    "\n",
    "amount_to_get = 1.0\n",
    "\n",
    "# Create function to separate a random amount of data\n",
    "def get_subset(image_path=data_path,\n",
    "               data_splits=[\"train\", \"test\"], \n",
    "               target_classes=[\"pizza\", \"steak\", \"sushi\", \"hamburger\", \"apple_pie\"],\n",
    "               amount=0.1,\n",
    "               seed=42):\n",
    "    random.seed(42)\n",
    "    label_splits = {}\n",
    "    \n",
    "    # Get labels\n",
    "    for data_split in data_splits:\n",
    "        print(f\"[INFO] Creating image split for: {data_split}...\")\n",
    "        label_path = data_dir / \"food-101\" / \"meta\" / f\"{data_split}.txt\"\n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = [line.strip(\"\\n\") for line in f.readlines() if line.split(\"/\")[0] in target_classes] \n",
    "        \n",
    "        # Get random subset of target classes image ID's\n",
    "        number_to_sample = round(amount * len(labels))\n",
    "        print(f\"[INFO] Getting random subset of {number_to_sample} images for {data_split}...\")\n",
    "        sampled_images = random.sample(labels, k=number_to_sample)\n",
    "        \n",
    "        # Apply full paths\n",
    "        image_paths = [Path(str(image_path / sample_image) + \".jpg\") for sample_image in sampled_images]\n",
    "        label_splits[data_split] = image_paths\n",
    "    return label_splits\n",
    "        \n",
    "label_splits = get_subset(\n",
    "    image_path=data_path,\n",
    "    data_splits=[\"train\", \"test\"],\n",
    "    target_classes=target_classes,\n",
    "    amount=amount_to_get)\n",
    "label_splits[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23d449-1f78-4798-b1af-9d1077e97922",
   "metadata": {},
   "source": [
    "## Move training and testing images to dedicated folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f76b3-13dd-486e-8184-b205c69ffff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target directory path\n",
    "#target_dir_name = f\"../data/pizza_steak_sushi_applepie_hamburger_{str(int(amount_to_get*100))}_percent\"\n",
    "target_dir_name = f\"../data/food-101_{str(int(amount_to_get*100))}_percent\"\n",
    "print(f\"Creating directory: '{target_dir_name}'\")\n",
    "\n",
    "# Setup the directories\n",
    "target_dir = Path(target_dir_name)\n",
    "\n",
    "# Make the directories\n",
    "target_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e39fd-b091-4fbd-88ef-4dc4af77fcd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for image_split in label_splits.keys():\n",
    "    for image_path in label_splits[str(image_split)]:\n",
    "        dest_dir = target_dir / image_split / image_path.parent.stem / image_path.name\n",
    "        if not dest_dir.parent.is_dir():\n",
    "            dest_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"[INFO] Copying {image_path} to {dest_dir}...\")\n",
    "        shutil.copy2(image_path, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a2970-a67d-46e6-ac92-c6020587abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check lengths of directories\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  import os\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "    \n",
    "walk_through_dir(target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53436482-2b03-473a-89a4-e51d3d57ab80",
   "metadata": {},
   "source": [
    "There is a total of 750 images per class for training and 250 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imagenet-downloader pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import requests\n",
    "from imagenet_downloader import download\n",
    "\n",
    "# Set your ImageNet credentials\n",
    "IMAGENET_USERNAME = \"your_username\"\n",
    "IMAGENET_ACCESS_TOKEN = \"your_access_token\"\n",
    "\n",
    "# Path to save images\n",
    "DOWNLOAD_DIR = \"./imagenet_unknown\"\n",
    "\n",
    "# Function to download images for a given synset\n",
    "def download_images(synset_id, num_images, split, output_dir):\n",
    "    target_dir = os.path.join(output_dir, split, synset_id)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    print(f\"Downloading {num_images} images for {synset_id} into {target_dir}...\")\n",
    "    download(\n",
    "        username=IMAGENET_USERNAME,\n",
    "        accesskey=IMAGENET_ACCESS_TOKEN,\n",
    "        wnid=synset_id,\n",
    "        output_dir=target_dir,\n",
    "        num_images=num_images\n",
    "    )\n",
    "    print(f\"Completed downloading for {synset_id}.\")\n",
    "\n",
    "# Define random synsets (non-food related)\n",
    "synsets = [\n",
    "    \"n01440764\",  # Tench\n",
    "    \"n01530575\",  # Brambling\n",
    "    \"n01629819\",  # European fire salamander\n",
    "    \"n01770393\",  # Scorpion\n",
    "    \"n01843383\",  # Toucan\n",
    "    \"n02102040\",  # English springer\n",
    "    \"n02951358\",  # Canoe\n",
    "    \"n03272010\",  # Electric guitar\n",
    "    \"n03876231\",  # Paintbrush\n",
    "    \"n04591713\",  # Wine bottle\n",
    "]\n",
    "\n",
    "# Randomly select 5 synsets for training and 5 for testing\n",
    "random.shuffle(synsets)\n",
    "train_synsets = synsets[:5]\n",
    "test_synsets = synsets[5:]\n",
    "\n",
    "# Download training images\n",
    "for synset in train_synsets:\n",
    "    download_images(synset_id=synset, num_images=100, split=\"train\", output_dir=DOWNLOAD_DIR)\n",
    "\n",
    "# Download test images\n",
    "for synset in test_synsets:\n",
    "    download_images(synset_id=synset, num_images=50, split=\"test\", output_dir=DOWNLOAD_DIR)\n",
    "\n",
    "print(\"Download completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
