{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This notebook prepares the images for a new class called \"unknown\". This class will be build using images from the [iFood-2019 dataset](https://www.kaggle.com/competitions/ifood-2019-fgvc6/data) dataset that contains 251 food types. This dataset can be considered as an extension of our target Food-101 dataset, so some of these 251 types already exist in the Food-101 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unknown Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and creating taget directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "from modules.helper_functions import create_dataloaders\n",
    "from bing_image_downloader import downloader\n",
    "\n",
    "# Define some constants\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "BATCH_SIZE = 64\n",
    "AMOUNT_TO_GET = 1.0\n",
    "SEED = 42\n",
    "\n",
    "# Define target data directory\n",
    "target_dir_food101_name = f\"../data/food-101_{str(int(AMOUNT_TO_GET*100))}_percent\"\n",
    "target_dir_food101_name_unknown = f\"../data/food-101_{str(int(AMOUNT_TO_GET*100))}_percent_unknown\"\n",
    "\n",
    "# Setup training and test directories\n",
    "target_dir_food101 = Path(target_dir_food101_name)\n",
    "train_dir_food101 = target_dir_food101 / \"train\"\n",
    "test_dir_food101 = target_dir_food101 / \"test\"\n",
    "\n",
    "# Create unknown directores\n",
    "target_dir_food101_unknown = Path(target_dir_food101_name_unknown)\n",
    "train_dir_food101_unknown = target_dir_food101_unknown / \"train\" / \"unknown\"\n",
    "test_dir_food101_unknown = target_dir_food101_unknown / \"test\" / \"unknown\"\n",
    "target_dir_food101_unknown.mkdir(parents=True, exist_ok=True)\n",
    "train_dir_food101_unknown.mkdir(parents=True, exist_ok=True)\n",
    "test_dir_food101_unknown.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target model directory\n",
    "model_dir = Path(\"../models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the class names for the Food101 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size\n",
    "IMG_SIZE = 384\n",
    "\n",
    "# Manual transforms for the training dataset\n",
    "manual_transforms = v2.Compose([           \n",
    "    v2.RandomCrop((IMG_SIZE, IMG_SIZE)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),    \n",
    "])\n",
    "\n",
    "# ViT-Base transforms\n",
    "# Manual transforms for the training dataset\n",
    "manual_transforms_aug_norm_train_vitb = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.CenterCrop((IMG_SIZE, IMG_SIZE)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Manual transforms for the test dataset\n",
    "manual_transforms_aug_norm_test_vitb = v2.Compose([    \n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.CenterCrop((IMG_SIZE, IMG_SIZE)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Get the class names for the Food101 dataset\n",
    "_, _, classes_food101_list = create_dataloaders(\n",
    "    train_dir=train_dir_food101,\n",
    "    test_dir=test_dir_food101,\n",
    "    train_transform=manual_transforms_aug_norm_train_vitb,\n",
    "    test_transform=manual_transforms_aug_norm_test_vitb,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = [len(list(Path(train_dir_food101).glob(f\"**/{classes}/*.jpg\"))) for classes in classes_food101_list]\n",
    "n_samples_test = [len(list(Path(test_dir_food101).glob(f\"**/{classes}/*.jpg\"))) for classes in classes_food101_list]\n",
    "#test_image_path_list = list(Path(train_dir).glob(\"**/apple_pie/*.jpg\")) # get list all image paths from test data \n",
    "#test_image_path_list\n",
    "len(n_samples_train), len(n_samples_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the ifood-2019 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir_food251_name = \"../data/ifood-2019-fgvc6\"\n",
    "\n",
    "# Setup training and test directories\n",
    "target_dir_food251 = Path(target_dir_food251_name)\n",
    "train_dir_food251 = target_dir_food251 / \"train_set\"\n",
    "val_dir_food251 = target_dir_food251 / \"val_set\"\n",
    "\n",
    "# Path to the file\n",
    "class_file_path = target_dir_food251 / \"class_list.txt\"\n",
    "train_labels_path = target_dir_food251 / \"train_labels.csv\"\n",
    "val_labels_path = target_dir_food251 / \"val_labels.csv\"\n",
    "\n",
    "# Initialize an empty list to store class names\n",
    "classes_food251_dict = {}\n",
    "\n",
    "# Open and read the file\n",
    "with open(class_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line into components\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        if len(parts) > 1:\n",
    "            classes_food251_dict.update({int(parts[0]): parts[1]})            \n",
    "\n",
    "# Print the result\n",
    "print(classes_food251_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the remaining classes—those in iFood-2019 that do not belong to Food-101—also involves cleaning the class names, such as through lemmatization, to achieve a good match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply lemmatization\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "classes_food101_lem_list = [lemmatizer.lemmatize(word) for word in classes_food101_list]\n",
    "classes_food251_lem_dict = {key: lemmatizer.lemmatize(word) for key, word in classes_food251_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look the classes in food101 that still end with \"s\" and replace them\n",
    "classes_food101_lem_list = [c[:-1] if c.endswith(\"s\") else c for c in classes_food101_list]\n",
    "\n",
    "# And check it out\n",
    "for c in classes_food101_lem_list:\n",
    "    if c.endswith(\"s\"):\n",
    "        print(c)\n",
    "\n",
    "classes_food101_lem_list = [c.replace(\"_\", \"\") for c in classes_food101_lem_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look the classes in food251 that still end with \"s\" and replace them\n",
    "classes_food251_lem_dict = {key: c[:-1] if c.endswith(\"s\") else c for key, c in classes_food251_dict.items()}\n",
    "\n",
    "# And check it out\n",
    "for c in classes_food251_lem_dict.values():\n",
    "    if c.endswith(\"s\"):\n",
    "        print(c)\n",
    "classes_food251_lem_dict = {key: c.replace(\"_\", \"\") for key, c in classes_food251_lem_dict.items()}\n",
    "\n",
    "# Create a new dictionary excluding steak related classes, because the \"steak\" class in food101 is too generic\n",
    "classes_food251_lem_dict = {key: val for key, val in classes_food251_lem_dict.items() if val != 'entrecote'}\n",
    "classes_food251_lem_dict = {key: val for key, val in classes_food251_lem_dict.items() if not('steak' in val)}\n",
    "classes_food251_lem_dict = {\n",
    "    key: val \n",
    "    for key, val in classes_food251_lem_dict.items() \n",
    "    if not any(val in food for food in classes_food101_lem_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how many images per remaining class should contain the new unknown class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how many images per remaining class should contain the new unknown class\n",
    "remaining_classes = set(classes_food251_lem_dict.values()) - set(classes_food101_lem_list)\n",
    "remaining_classes_dict = {key: value for key, value in classes_food251_lem_dict.items() if value in remaining_classes}\n",
    "n_samples_per_remaining_class_train = round(np.mean(n_samples_train) / len(remaining_classes) + 0.5)\n",
    "n_samples_per_remaining_class_test = round(np.mean(n_samples_test) / len(remaining_classes) + 0.5)\n",
    "print(f\"Number of remaining classes: {len(remaining_classes_dict)}\")\n",
    "print(f\"Number of samples per remaining class for training: {n_samples_per_remaining_class_train}\")\n",
    "print(f\"Number of samples per remaining class for training: {n_samples_per_remaining_class_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame that contains the image name, label, and class name of the remaning image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the reamining classes  \n",
    "df_remaining_classes = pd.DataFrame(remaining_classes_dict.items(), columns=['label', 'class'])\n",
    "df_train_labels = pd.read_csv(train_labels_path)\n",
    "df_val_labels = pd.read_csv(val_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the dataframe with labels\n",
    "df_remaining_train_labels = df_train_labels.merge(df_remaining_classes, how='right', on='label')\n",
    "df_remaining_val_labels = df_val_labels.merge(df_remaining_classes, how='right', on='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the result\n",
    "df_remaining_train_labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copies a random selection of image files from the source directory to the destination directory based on labels provided in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_random_samples(df, source_dir, destination_dir, n_samples_per_class, seed):\n",
    "    \"\"\"\n",
    "    Copy random samples from the source directory to the destination directory.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the labels and image names.\n",
    "        source_dir (str): Path to the source directory.\n",
    "        destination_dir (str): Path to the destination directory.\n",
    "        n_samples_per_class (int): Number of samples to copy per class.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "    # Loop over each label\n",
    "    for _, group in df.groupby('label'):\n",
    "        # Sample the group and take the image names \n",
    "        selected_files = group.sample(n=n_samples_per_class, random_state=seed)['img_name'].tolist()\n",
    "        # Copy the selected files into the destination directory\n",
    "        for file in selected_files:\n",
    "            source_path = os.path.join(source_dir, file)\n",
    "            destination_path = os.path.join(destination_dir, file)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "\n",
    "copy_random_samples(df_remaining_train_labels, train_dir_food251, train_dir_food101_unknown, n_samples_per_remaining_class_train, SEED)\n",
    "copy_random_samples(df_remaining_val_labels, val_dir_food251, test_dir_food101_unknown, n_samples_per_remaining_class_test, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extented the Unknow Class with New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download other typical food types to be added to the unknown category\n",
    "other_images = ['capuccino cup', 'coffee', 'banana', 'obst', 'apfel', 'orange fruit', 'fruit basket', 'smoothie', 'dorade', 'kabeljau']\n",
    "#for item in other_images:\n",
    "#    downloader.download(item, limit=25, output_dir='images', adult_filter_off=True, force_replace=False, timeout=60, filter=\"photo, clipart\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"train\" and \"test\" directories if they don't exist\n",
    "other_image_folder = Path('images')\n",
    "other_image_folder_train = other_image_folder / 'train'\n",
    "other_image_folder_test = other_image_folder / 'test'\n",
    "other_image_folder_train.mkdir(parents=True, exist_ok=True)\n",
    "other_image_folder_test.mkdir(parents=True, exist_ok=True)  \n",
    "\n",
    "# Loop through each category in \"other_images\"\n",
    "for category in other_images:\n",
    "    # List the files for this category (assumes the images are named according to the category)\n",
    "    category_folder = os.path.join(other_image_folder, category)\n",
    "    \n",
    "    # Check if the category folder exists\n",
    "    if os.path.exists(category_folder):\n",
    "        # Get all image filenames for this category\n",
    "        images_orig = [img for img in os.listdir(category_folder) if img.lower().endswith(('.jpg', '.jpeg'))]\n",
    "        images_renamed = [image.replace('.',f'_{category}.') for image in images_orig]\n",
    "        images_renamed = [image.replace(' ','_') for image in images_renamed]\n",
    "\n",
    "        # Shuffle the image filenames randomly\n",
    "        random.seed(SEED+random.randint(1, 1000))\n",
    "        random.shuffle(images_orig)\n",
    "        random.shuffle(images_renamed)\n",
    "\n",
    "\n",
    "        # Move 6 images to the \"train\" folder\n",
    "        for idx, img in enumerate(images_orig[:6]):\n",
    "            src_orig = os.path.join(category_folder, img)\n",
    "            dst_orig = os.path.join(train_dir_food101_unknown, images_renamed[idx])\n",
    "            dst_renamed = os.path.join(train_dir_food101_unknown, images_renamed[idx])\n",
    "            shutil.copy(src_orig, dst_orig)\n",
    "            shutil.move(dst_orig, dst_renamed)\n",
    "\n",
    "        # Move 2 images to the \"test\" folder\n",
    "        for idx, img in enumerate(images_orig[6:8]):\n",
    "            src_orig = os.path.join(category_folder, img)\n",
    "            dst_orig = os.path.join(test_dir_food101_unknown, images_renamed[idx])\n",
    "            dst_renamed = os.path.join(test_dir_food101_unknown, images_renamed[idx])\n",
    "            shutil.copy(src_orig, dst_orig)\n",
    "            shutil.move(dst_orig, dst_renamed)\n",
    "\n",
    "        print(f\"Moved 6 images of {category} to 'train' and 2 images to 'test'.\")\n",
    "    else:\n",
    "        print(f\"Category folder '{category}' not found. Skipping...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
