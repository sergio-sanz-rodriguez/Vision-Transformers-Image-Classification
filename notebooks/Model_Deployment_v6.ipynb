{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will create a proof-on-concept web application that shows the finally selected model in accion. The application will be created using the [Gradio](https://www.gradio.app/) framework and then deployed to HuggingFace to make it publicly available for all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Directories and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FoodVision demo path\n",
    "food_vision_demo_path = Path(\"../demo\")  # Path joining with Path objects\n",
    "food_vision_demo_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make examples directory\n",
    "food_vision_demo_examples_path = food_vision_demo_path / \"examples\"\n",
    "food_vision_demo_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Specify model directory\n",
    "food_vision_model_path = Path(\"../models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Food Description File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON file with the description of th 101 types of food\n",
    "food_descriptions = {\n",
    "    \"apple_pie\": \"A classic American dessert made with spiced apple filling encased in a flaky pastry crust, often served with ice cream.\",\n",
    "    \"baby_back_ribs\": \"Juicy, tender pork ribs, slow-cooked and coated with a flavorful barbecue sauce.\",\n",
    "    \"baklava\": \"A rich, sweet pastry layered with chopped nuts and honey or syrup, originating from the Middle East and Mediterranean regions.\",\n",
    "    \"beef_carpaccio\": \"Thinly sliced raw beef served with olive oil, lemon, capers, and Parmesan, often as a starter.\",\n",
    "    \"beef_tartare\": \"Finely chopped or ground raw beef mixed with seasonings like capers, onions, and egg yolk, served uncooked.\",\n",
    "    \"beet_salad\": \"A refreshing dish featuring cooked or raw beets paired with greens, goat cheese, nuts, and a tangy vinaigrette.\",\n",
    "    \"beignets\": \"Deep-fried dough pastries dusted with powdered sugar, popular in New Orleans as a sweet treat.\",\n",
    "    \"bibimbap\": \"A Korean mixed rice dish topped with vegetables, meat, an egg, and spicy gochujang sauce.\",\n",
    "    \"bread_pudding\": \"A comforting dessert made from bread soaked in a sweet custard mixture and baked until golden.\",\n",
    "    \"breakfast_burrito\": \"A hearty wrap filled with scrambled eggs, cheese, meats, and sometimes vegetables or beans.\",\n",
    "    \"bruschetta\": \"An Italian appetizer of toasted bread rubbed with garlic and topped with fresh tomatoes, olive oil, and basil.\",\n",
    "    \"caesar_salad\": \"A classic salad made with romaine lettuce, croutons, Parmesan cheese, and Caesar dressing.\",\n",
    "    \"cannoli\": \"An Italian dessert consisting of a crispy pastry shell filled with sweet ricotta cheese and sometimes chocolate chips.\",\n",
    "    \"caprese_salad\": \"A simple Italian salad of fresh mozzarella, tomatoes, and basil, drizzled with olive oil and balsamic vinegar.\",\n",
    "    \"carrot_cake\": \"A moist cake made with grated carrots and often topped with cream cheese frosting.\",\n",
    "    \"ceviche\": \"A seafood dish where fresh fish or shrimp is 'cooked' in citrus juice and mixed with onions, peppers, and cilantro.\",\n",
    "    \"cheese_plate\": \"An assortment of cheeses served with accompaniments like crackers, fruit, and nuts.\",\n",
    "    \"cheesecake\": \"A creamy dessert made with a mixture of cream cheese, sugar, and eggs on a graham cracker or pastry crust.\",\n",
    "    \"chicken_curry\": \"A flavorful dish of chicken cooked in a spicy, aromatic curry sauce, popular in South Asian cuisine.\",\n",
    "    \"chicken_quesadilla\": \"A Mexican dish of tortillas filled with cheese, chicken, and spices, grilled until crispy and melty.\",\n",
    "    \"chicken_wings\": \"Juicy chicken wings fried or baked and often coated with a tangy or spicy sauce.\",\n",
    "    \"chocolate_cake\": \"A rich, moist dessert made with layers of chocolate sponge and frosting.\",\n",
    "    \"chocolate_mousse\": \"A light and creamy dessert made with whipped cream and melted chocolate, often served chilled.\",\n",
    "    \"churros\": \"Fried dough pastry, often coated in sugar and cinnamon, typically served with chocolate dipping sauce.\",\n",
    "    \"clam_chowder\": \"A creamy soup made with clams, potatoes, and onions, often served in a bread bowl.\",\n",
    "    \"club_sandwich\": \"A layered sandwich filled with turkey, bacon, lettuce, tomato, and mayonnaise.\",\n",
    "    \"crab_cakes\": \"Pan-fried or baked patties made from lump crab meat and breadcrumbs, seasoned with spices.\",\n",
    "    \"creme_brulee\": \"A custard dessert with a caramelized sugar crust on top, served cold.\",\n",
    "    \"croque_madame\": \"A French grilled sandwich filled with ham and cheese, topped with a fried egg.\",\n",
    "    \"cup_cakes\": \"Small, individual-sized cakes often topped with frosting and decorations.\",\n",
    "    \"deviled_eggs\": \"Hard-boiled eggs halved and filled with a seasoned yolk mixture.\",\n",
    "    \"donuts\": \"Sweet, fried dough pastries, often glazed or topped with sprinkles.\",\n",
    "    \"dumplings\": \"Small dough parcels filled with meat or vegetables, steamed, boiled, or fried.\",\n",
    "    \"edamame\": \"Boiled or steamed young soybeans served in their pods, sprinkled with salt.\",\n",
    "    \"eggs_benedict\": \"A breakfast dish of poached eggs, English muffins, Canadian bacon, and hollandaise sauce.\",\n",
    "    \"escargots\": \"Cooked snails, often served with garlic butter in French cuisine.\",\n",
    "    \"falafel\": \"Deep-fried balls or patties made from ground chickpeas or fava beans, often served in pita bread.\",\n",
    "    \"filet_mignon\": \"A tender and juicy cut of beef steak, often served as a fine dining dish.\",\n",
    "    \"fish_and_chips\": \"A classic British dish of battered and fried fish served with crispy fries.\",\n",
    "    \"foie_gras\": \"A French delicacy made from the liver of a fattened duck or goose, often served as a pâté.\",\n",
    "    \"french_fries\": \"Thinly sliced potatoes deep-fried until crispy, often served as a side dish.\",\n",
    "    \"french_onion_soup\": \"A hearty soup made with caramelized onions and beef broth, topped with bread and melted cheese.\",\n",
    "    \"french_toast\": \"Bread slices soaked in a milk and egg mixture, fried until golden, and served with syrup.\",\n",
    "    \"fried_calamari\": \"Lightly battered and fried squid rings, often served with marinara or aioli sauce.\",\n",
    "    \"fried_rice\": \"A stir-fried rice dish mixed with vegetables, eggs, and meat or seafood.\",\n",
    "    \"frozen_yogurt\": \"A creamy, tangy dessert similar to ice cream but made with yogurt.\",\n",
    "    \"garlic_bread\": \"Toasted bread slices flavored with garlic butter, often served as a side dish.\",\n",
    "    \"gnocchi\": \"Soft Italian dumplings made from potato, flour, and sometimes cheese, served with sauce.\",\n",
    "    \"greek_salad\": \"A fresh salad made with cucumbers, tomatoes, olives, feta cheese, and olive oil.\",\n",
    "    \"grilled_cheese_sandwich\": \"A hot sandwich filled with melted cheese, grilled until crispy.\",\n",
    "    \"grilled_salmon\": \"Salmon fillets cooked on a grill, often seasoned with herbs and spices.\",\n",
    "    \"guacamole\": \"A creamy dip made from mashed avocados, lime juice, onions, and cilantro.\",\n",
    "    \"gyoza\": \"Japanese dumplings filled with minced meat and vegetables, pan-fried and steamed.\",\n",
    "    \"hamburger\": \"A ground beef patty served in a bun with toppings like lettuce, tomato, and cheese.\",\n",
    "    \"hot_and_sour_soup\": \"A Chinese soup with a tangy and spicy flavor, filled with tofu, mushrooms, and vegetables.\",\n",
    "    \"hot_dog\": \"A grilled or boiled sausage served in a bun with condiments like ketchup and mustard.\",\n",
    "    \"huevos_rancheros\": \"A Mexican breakfast dish with fried eggs, tortillas, and salsa.\",\n",
    "    \"hummus\": \"A creamy dip made from blended chickpeas, tahini, lemon juice, and garlic.\",\n",
    "    \"ice_cream\": \"A frozen dessert made from sweetened cream, often flavored and served in scoops.\",\n",
    "    \"lasagna\": \"An Italian pasta dish layered with meat, cheese, and tomato sauce, baked until bubbly.\",\n",
    "    \"lobster_bisque\": \"A creamy soup made from lobster stock, often served as a gourmet dish.\",\n",
    "    \"lobster_roll_sandwich\": \"A sandwich filled with chunks of lobster meat, dressed in butter or mayo.\",\n",
    "    \"macaroni_and_cheese\": \"A comfort food dish of macaroni pasta mixed with a creamy cheese sauce.\",\n",
    "    \"macarons\": \"Delicate French almond cookies filled with flavored buttercream or ganache.\",\n",
    "    \"miso_soup\": \"A Japanese soup made with fermented soybean paste, tofu, and seaweed.\",\n",
    "    \"mussels\": \"Shellfish steamed and served in a flavorful broth, often with bread.\",\n",
    "    \"nachos\": \"Tortilla chips topped with melted cheese and various toppings like jalapeños and sour cream.\",\n",
    "    \"omelette\": \"Beaten eggs cooked in a frying pan, often filled with cheese, meats, or vegetables.\",\n",
    "    \"onion_rings\": \"Crispy, deep-fried onion slices, often served as a side dish or snack.\",\n",
    "    \"oysters\": \"Shellfish often served raw on the half shell with lemon or hot sauce.\",\n",
    "    \"pad_thai\": \"Stir-fried rice noodles with eggs, tofu or shrimp, peanuts, and a tamarind-based sauce.\",\n",
    "    \"paella\": \"Spanish rice dish with seafood, meats, and saffron, traditionally cooked in a single pan.\",\n",
    "    \"pancakes\": \"Fluffy round cakes made from flour, eggs, and milk, served with syrup and butter.\",\n",
    "    \"panna_cotta\": \"Italian dessert of sweetened cream thickened with gelatin, often topped with berries or caramel.\",\n",
    "    \"peking_duck\": \"Crispy duck served with pancakes, hoisin sauce, and sliced scallions.\",\n",
    "    \"pho\": \"Vietnamese noodle soup with broth, rice noodles, herbs, and beef or chicken.\",\n",
    "    \"pizza\": \"Flat dough topped with tomato sauce, cheese, and various toppings, baked until crispy.\",\n",
    "    \"pork_chop\": \"Grilled or roasted cut of pork, often served with vegetables or a flavorful sauce.\",\n",
    "    \"poutine\": \"Canadian dish with French fries, cheese curds, and gravy.\",\n",
    "    \"prime_rib\": \"Tender beef rib roast, often seasoned and slow-cooked, served for special occasions.\",\n",
    "    \"pulled_pork_sandwich\": \"Slow-cooked shredded pork with barbecue sauce, served on a bun.\",\n",
    "    \"ramen\": \"Japanese noodle soup with broth, wheat noodles, and toppings like eggs and pork.\",\n",
    "    \"ravioli\": \"Italian dumplings filled with cheese, meat, or vegetables, served with sauce.\",\n",
    "    \"red_velvet_cake\": \"Rich cake with a hint of cocoa and red coloring, layered with cream cheese frosting.\",\n",
    "    \"risotto\": \"Italian creamy rice dish cooked with broth and flavored with vegetables or meat.\",\n",
    "    \"samosa\": \"Deep-fried pastry filled with spiced potatoes, peas, and sometimes meat.\",\n",
    "    \"sashimi\": \"Thinly sliced raw fish or seafood, often served with soy sauce and wasabi.\",\n",
    "    \"scallops\": \"Delicate shellfish, often seared and served as a seafood entrée.\",\n",
    "    \"seaweed_salad\": \"Salad made from seasoned edible seaweed, typically with sesame oil and soy sauce.\",\n",
    "    \"shrimp_and_grits\": \"Southern dish of shrimp cooked in a savory sauce, served with creamy grits.\",\n",
    "    \"spaghetti_bolognese\": \"Italian pasta with a rich meat sauce made from ground beef, tomatoes, and herbs.\",\n",
    "    \"spaghetti_carbonara\": \"Pasta with a creamy sauce made from eggs, cheese, pancetta, and black pepper.\",\n",
    "    \"spring_rolls\": \"Rice paper rolls filled with vegetables, meat, or seafood, served with dipping sauce.\",\n",
    "    \"steak\": \"Grilled or pan-seared beef cut, often served with vegetables or potatoes.\",\n",
    "    \"strawberry_shortcake\": \"Dessert with layers of cake, fresh strawberries, and whipped cream.\",\n",
    "    \"sushi\": \"Japanese dish with vinegared rice, raw or cooked seafood, and sometimes vegetables.\",\n",
    "    \"tacos\": \"Mexican dish with a tortilla filled with meat, vegetables, cheese, and salsa.\",\n",
    "    \"takoyaki\": \"Japanese snack made from batter, octopus, and tempura bits, served with takoyaki sauce.\",\n",
    "    \"tiramisu\": \"Italian dessert with coffee-soaked ladyfingers, mascarpone cheese, and cocoa powder.\",\n",
    "    \"tuna_tartare\": \"Finely diced raw tuna, often mixed with soy sauce and served as an appetizer.\",\n",
    "    \"unknown\": \"No sufficient confidence to classify the image.\",\n",
    "    \"waffles\": \"Batter-based dish cooked in a grid pattern, served with syrup, fruit, or whipped cream.\"\n",
    "}\n",
    "\n",
    "# \"The current picture is not recognized as one of the 101 food classes. Please try again.\"\n",
    "\n",
    "food_descriptions = {key.replace(\"_\", \" \"): value for key, value in food_descriptions.items()}\n",
    "\n",
    "# Save to JSON file\n",
    "food_descriptions_json = os.path.join(food_vision_demo_path, 'food_descriptions.json')\n",
    "with open(food_descriptions_json, 'w') as f:\n",
    "    json.dump(food_descriptions, f, indent=4)\n",
    "\n",
    "# Open JSON file\n",
    "# Load the food descriptions from the JSON file\n",
    "with open(food_descriptions_json, 'r') as f:\n",
    "    food_descriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Class Name File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Food-101 class names to ..\\demo\\class_names.txt\n",
      "[INFO] Reading Food-101 class names from ..\\demo\\class_names.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['apple pie', 'baby back ribs', 'baklava', 'beef carpaccio', 'beef tartare']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create path to Food-101 class names\n",
    "class_names = list(food_descriptions.keys())\n",
    "food_vision_class_names_path = food_vision_demo_path / \"class_names.txt\"\n",
    "\n",
    "# Write Food-101 class names list to file\n",
    "with open(food_vision_class_names_path, \"w\") as f:\n",
    "    print(f\"[INFO] Saving Food-101 class names to {food_vision_class_names_path}\")\n",
    "    f.write(\"\\n\".join(class_names)) # leave a new line between each class\n",
    "\n",
    "# Open Food-101 class names file\n",
    "with open(food_vision_class_names_path, \"r\") as f:\n",
    "    print(f\"[INFO] Reading Food-101 class names from {food_vision_class_names_path}\")\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    " # Show the first 5 class names\n",
    "class_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Creating Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an examples directory\n",
    "food_vision_examples_path = food_vision_demo_path / \"examples\"\n",
    "food_vision_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect five test image paths\n",
    "food_vision_examples = [Path('../data/food-101_100_percent/test/sushi/511665.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/hot_and_sour_soup/1134579.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/paella/2083247.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/carrot_cake/470617.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/pizza/3770514.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/pork_chop/137031.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/steak/144370.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/fried_calamari/936686.jpg')\n",
    "                        ]\n",
    "\n",
    "# Copy the images to the examples directory\n",
    "for example in food_vision_examples:\n",
    "    example_path = food_vision_examples_path / example.name\n",
    "    if not example_path.exists():\n",
    "        print(f\"[INFO] Copying {example} to {example_path}\")\n",
    "        shutil.copy(src=example, dst=example_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Creating the ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/model.py\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import softmax\n",
    "from pathlib import Path\n",
    "from vision_transformer import ViT\n",
    "\n",
    "def load_model(model: torch.nn.Module,\n",
    "               model_weights_dir: str,\n",
    "               model_weights_name: str):\n",
    "\n",
    "    \"\"\"Loads a PyTorch model from a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to load.\n",
    "    model_weights_dir: A directory where the model is located.\n",
    "    model_weights_name: The name of the model to load.\n",
    "      Should include either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    model = load_model(model=model,\n",
    "                       model_weights_dir=\"models\",\n",
    "                       model_weights_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "\n",
    "    Returns:\n",
    "    The loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the model directory path\n",
    "    model_dir_path = Path(model_weights_dir)\n",
    "\n",
    "    # Create the model path\n",
    "    assert model_weights_name.endswith(\".pth\") or model_weights_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_path = model_dir_path / model_weights_name\n",
    "\n",
    "    # Load the model\n",
    "    print(f\"[INFO] Loading model from: {model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_vitbase_model(\n",
    "    model_weights_dir:Path,\n",
    "    model_weights_name:str,\n",
    "    img_size:int=224,\n",
    "    num_classes:int=101,\n",
    "    compile:bool=False\n",
    "    ):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates a ViT-B/16 model with the specified number of classes.\n",
    "\n",
    "    Args:\n",
    "        model_weights_dir: A directory where the model is located.\n",
    "        model_weights_name: The name of the model to load.\n",
    "        img_size: The size of the input image.\n",
    "        num_classes: The number of classes for the classification task.\n",
    "\n",
    "    Returns:\n",
    "    The created ViT-B/16 model.\n",
    "    \"\"\" \n",
    "\n",
    "    # Instantiate the model\n",
    "    vitbase16_model = ViT(\n",
    "        img_size=img_size,\n",
    "        in_channels=3,\n",
    "        patch_size=16,\n",
    "        num_transformer_layers=12,\n",
    "        emb_dim=768,\n",
    "        mlp_size=3072,\n",
    "        num_heads=12,\n",
    "        attn_dropout=0,\n",
    "        mlp_dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # Compile the model\n",
    "    if compile:\n",
    "        vitbase16_model = torch.compile(vitbase16_model, backend=\"aot_eager\")\n",
    "\n",
    "    # Load the trained weights\n",
    "    vitbase16_model = load_model(\n",
    "        model=vitbase16_model,\n",
    "        model_weights_dir=model_weights_dir,\n",
    "        model_weights_name=model_weights_name\n",
    "        )\n",
    "    \n",
    "    return vitbase16_model\n",
    "\n",
    "# Create an EfficientNet-B0 Model\n",
    "def create_effnetb0(\n",
    "        model_weights_dir: Path,\n",
    "        model_weights_name: str,\n",
    "        num_classes: int=2,\n",
    "        dropout: float=0.2,\n",
    "        compile:bool=False\n",
    "        ):\n",
    "\n",
    "    \"\"\"Creates an EfficientNetB0 feature extractor model and transforms.\n",
    "\n",
    "    Args:\n",
    "        model_weights_dir: A directory where the model is located.\n",
    "        model_weights_name: The name of the model to load.\n",
    "        num_classes (int, optional): number of classes in the classifier head.\n",
    "        dropout (float, optional): Dropout rate. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        effnetb0_model (torch.nn.Module): EffNetB0 feature extractor model.\n",
    "        transforms (torchvision.transforms): Image transforms.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights \n",
    "    effnetb0_model = torchvision.models.efficientnet_b0(weights=weights).to('cpu')\n",
    "\n",
    "    # Recreate the classifier layer and seed it to the target device\n",
    "    if dropout != 0.0:\n",
    "        effnetb0_model.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=dropout, inplace=True), \n",
    "            torch.nn.Linear(in_features=1280, \n",
    "                            out_features=num_classes,\n",
    "                            bias=True))\n",
    "    else:\n",
    "        effnetb0_model.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=1280,\n",
    "                            out_features=num_classes,\n",
    "                            bias=True))\n",
    "    \n",
    "    # Compile the model\n",
    "    if compile:\n",
    "        effnetb0_model = torch.compile(effnetb0_model, backend=\"aot_eager\")\n",
    "    \n",
    "    # Create the model directory path\n",
    "    model_dir_path = Path(model_weights_dir)\n",
    "\n",
    "    # Create the model path\n",
    "    assert model_weights_name.endswith(\".pth\") or model_weights_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_path = model_dir_path / model_weights_name\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    effnetb0_model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "        \n",
    "    return effnetb0_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../demo/vision_transformer.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy required libraries\n",
    "shutil.copy(src=\"modules/vision_transformer.py\", dst=\"../demo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Creating the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/app.py\n",
    "\n",
    "# Imports and class names setup\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import string\n",
    "import gradio as gr\n",
    "from model import create_vitbase_model, create_effnetb0\n",
    "from timeit import default_timer as timer\n",
    "from typing import Tuple, Dict\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "# Specify class names\n",
    "food_vision_class_names_path = \"class_names.txt\"\n",
    "with open(food_vision_class_names_path, \"r\") as f:\n",
    "    class_names_102 = f.read().splitlines()\n",
    "class_names_101 = class_names_102.copy()\n",
    "class_names_101.remove(\"unknown\")\n",
    "\n",
    "# Specify number of classes\n",
    "num_classes_102 = len(class_names_102) # 101 + unknown\n",
    "num_classes_101 = len(class_names_101) # 101\n",
    "\n",
    "# Load the food description file\n",
    "food_descriptions_json = \"food_descriptions.json\"\n",
    "with open(food_descriptions_json, 'r') as f:\n",
    "    food_descriptions = json.load(f)\n",
    "\n",
    "# Instantiate the classfication model for recognizing between food and non-food images\n",
    "classification_model_name_path_1 = \"effnetb0_2025-01-05_epoch13.pth\"\n",
    "effnetb0_model_1 = create_effnetb0(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=classification_model_name_path_1,\n",
    "    num_classes=2,\n",
    "    compile=True,\n",
    "    dropout=0.2\n",
    "    )\n",
    "\n",
    "# Instantiate the model for recognizing between known and unknown food images\n",
    "classification_model_name_path_2 = \"effnetb0_2_2025-01-12_epoch13.pth\"\n",
    "effnetb0_model_2 = create_effnetb0(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=classification_model_name_path_2,\n",
    "    num_classes=2,\n",
    "    compile=True,\n",
    "    dropout=0.0\n",
    "    )\n",
    "\n",
    "# Load the ViT-Base/16 transformer with input image of 384x384 pixels and 101 + unknown classes\n",
    "vitbase_model_102 = create_vitbase_model(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=\"vitbase16_102_2025-01-04.pth\",\n",
    "    img_size=384,\n",
    "    num_classes=num_classes_102,\n",
    "    compile=True\n",
    ")\n",
    "\n",
    "vitbase_model_101 = create_vitbase_model(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=\"vitbase16_2_2024-12-31.pth\",\n",
    "    img_size=384,\n",
    "    num_classes=num_classes_101,\n",
    "    compile=True\n",
    ")\n",
    "\n",
    "# Specify manual transforms for ViTs\n",
    "transforms_eff = v2.Compose([    \n",
    "    v2.Resize((256, 256)),\n",
    "    v2.CenterCrop((224, 224)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Specify manual transforms for ViTs\n",
    "transforms_vit = v2.Compose([    \n",
    "    v2.Resize((384)), #v2.Resize((384, 384)),\n",
    "    v2.CenterCrop((384, 384)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "\n",
    "# Put models into evaluation mode and turn on inference mode\n",
    "effnetb0_model_1.eval()\n",
    "effnetb0_model_2.eval()\n",
    "vitbase_model_102.eval()\n",
    "vitbase_model_101.eval()\n",
    "\n",
    "# Set thresdholds\n",
    "BINARY_CLASSIF_THR_1 = 0.8310611844062805\n",
    "BINARY_CLASSIF_THR_2 = 0.06102316826581955 # 41% FPR\n",
    "#BINARY_CLASSIF_THR_2 = 0.0728086531162262  # 23% FPR\n",
    "MULTICLASS_CLASSIF_THR = 0.5\n",
    "ENTROPY_THR = 2.7\n",
    "\n",
    "# Set model names\n",
    "lite_model = \"⚡ ViT Lite ⚡ faster, less accurate prediction\"\n",
    "pro_model =  \"💎 ViT Pro 💎 slower, more accurate prediction\"\n",
    "\n",
    "# Computes the entropy\n",
    "def entropy(pred_probs):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the entropy of the predicted probabilities.\n",
    "\n",
    "    Args:\n",
    "        pred_probs (torch.Tensor): A tensor containing the predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        float: The entropy value.\n",
    "    \"\"\"\n",
    "\n",
    "    return -torch.sum(pred_probs * torch.log(pred_probs)).item()\n",
    "\n",
    "# Computes the model prediction outputs as probabilities\n",
    "def predict(image, model):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the predicted class probabilities for a given image using the provided model.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input tensor representing the image or batch of images.\n",
    "                              The tensor should be preprocessed as required by the model.\n",
    "        model (torch.nn.Module): The trained model used to make predictions.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the probabilities for each class. \n",
    "                      The output is normalized using the softmax function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.softmax(model(image), dim=1)\n",
    "\n",
    "# Predict method\n",
    "def classify_food(image, model=pro_model) -> Tuple[Dict, str, str]:\n",
    "\n",
    "    \"\"\"\n",
    "    Transforms and performs a prediction on the image and returns prediction details.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input tensor representing the image.\n",
    "                              It should be preprocessed as required by the model.\n",
    "        model (torch.nn.Module, optional): The trained model used for predictions.\n",
    "                                           Defaults to pro_model.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict, str, str]: A tuple containing:\n",
    "            - Dictionary of predicted class probabilities.\n",
    "            - Time taken for prediction as a string.\n",
    "            - Description of the top predicted class.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Start the timer\n",
    "        start_time = timer()\n",
    "\n",
    "        # Transform the target image and add a batch dimension\n",
    "        image_eff = transforms_eff(image).unsqueeze(0)\n",
    "\n",
    "        # Check out model parameter\n",
    "        if model == None:\n",
    "            model = pro_model\n",
    "        \n",
    "        # Make prediction...\n",
    "        with torch.inference_mode():\n",
    "            \n",
    "            # If the picture is food\n",
    "            if predict(image_eff, effnetb0_model_1)[:,1] >= BINARY_CLASSIF_THR_1:\n",
    "\n",
    "                image_vit = transforms_vit(image).unsqueeze(0)\n",
    "\n",
    "                # If ViT Pro\n",
    "                if model == pro_model:\n",
    "\n",
    "                    # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
    "                    pred_probs_102 = predict(image_vit, vitbase_model_102)\n",
    "                    pred_probs_101 = predict(image_vit, vitbase_model_101)\n",
    "\n",
    "                    # Create a prediction label and prediction probability dictionary for each prediction class\n",
    "                    pred_classes_and_probs_102 = {class_names_102[i]: float(pred_probs_102[0][i]) for i in range(num_classes_102)}\n",
    "                    pred_classes_and_probs_101 = {class_names_101[i]: float(pred_probs_101[0][i]) for i in range(num_classes_101)}\n",
    "                    pred_classes_and_probs_101[\"unknown\"] = 0.0\n",
    "\n",
    "                    # Get the top predicted class\n",
    "                    top_class_102 = max(pred_classes_and_probs_102, key=pred_classes_and_probs_102.get)\n",
    "                    sec_class_102 = sorted(pred_classes_and_probs_102.items(), key=lambda x: x[1], reverse=True)[1][0]\n",
    "                    top_class_101 = max(pred_classes_and_probs_101, key=pred_classes_and_probs_101.get)                    \n",
    "\n",
    "                    # If the image is likely to be an known category\n",
    "                    if  predict(image_eff, effnetb0_model_2)[:,1] >= BINARY_CLASSIF_THR_2:\n",
    "\n",
    "                        # Compare the predictions of the two transformer models                    \n",
    "                        if ((top_class_101 == sec_class_102) and (top_class_102 == \"unknown\")) or (top_class_101 == top_class_102):\n",
    "                            \n",
    "                            # Get the probability vector\n",
    "                            pred_classes_and_probs = pred_classes_and_probs_101\n",
    "\n",
    "                            # Get the top predicted class\n",
    "                            top_class = top_class_101\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            # Get the probability vector\n",
    "                            pred_classes_and_probs = pred_classes_and_probs_102\n",
    "\n",
    "                            # Get the top predicted class\n",
    "                            top_class = top_class_102\n",
    "\n",
    "                    # The food is unknown\n",
    "                    else:\n",
    "\n",
    "                        # Set all probabilites to zero except class unknown\n",
    "                        pred_classes_and_probs = {class_names_101[i]: 0.0 for i in range(num_classes_101)}\n",
    "                        pred_classes_and_probs[\"unknown\"] = 1.0\n",
    "            \n",
    "                        # Get the top predicted class\n",
    "                        top_class = \"unknown\"\n",
    "\n",
    "                # ViT Lite\n",
    "                else:\n",
    "\n",
    "                    # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
    "                    pred_probs_101 = predict(image_vit, vitbase_model_101) # 101 classes\n",
    "\n",
    "                    # Calculate entropy\n",
    "                    entropy_101 = entropy(pred_probs_101)\n",
    "\n",
    "                    # Create a prediction label and prediction probability dictionary for each prediction class\n",
    "                    pred_classes_and_probs = {class_names_101[i]: float(pred_probs_101[0][i]) for i in range(num_classes_101)}\n",
    "                    pred_classes_and_probs[\"unknown\"] = 0.0\n",
    "\n",
    "                    # Get the top predicted class\n",
    "                    top_class = max(pred_classes_and_probs, key=pred_classes_and_probs.get)\n",
    "\n",
    "                    # If the image is likely to be an unknown category\n",
    "                    if pred_probs_101[0][class_names_101.index(top_class)] <= MULTICLASS_CLASSIF_THR and entropy_101 > ENTROPY_THR:\n",
    "\n",
    "                        # Create prediction label and prediction probability for class unknown and rescale the rest of predictions\n",
    "                        pred_classes_and_probs[\"unknown\"] = pred_probs_101.max() * 1.25\n",
    "                        prob_sum = sum(pred_classes_and_probs.values())\n",
    "                        pred_classes_and_probs = {key: value / prob_sum for key, value in pred_classes_and_probs.items()}\n",
    "\n",
    "                        # Get the top predicted class\n",
    "                        top_class = \"unknown\"\n",
    "                        \n",
    "            # Otherwise\n",
    "            else:\n",
    "\n",
    "                # Set all probabilites to zero except class unknown\n",
    "                pred_classes_and_probs = {class_names_101[i]: 0.0 for i in range(num_classes_101)}\n",
    "                pred_classes_and_probs[\"unknown\"] = 1.0\n",
    "            \n",
    "                # Get the top predicted class\n",
    "                top_class = \"unknown\"\n",
    "\n",
    "        \n",
    "        # Get the description of the top predicted class\n",
    "        top_class_description = food_descriptions.get(top_class, \"Description not available.\")\n",
    "\n",
    "        # Calculate the prediction time\n",
    "        pred_time = f\"{round(timer() - start_time, 1)} s.\"\n",
    "        \n",
    "        # Return the prediction dictionary and prediction time \n",
    "        return pred_classes_and_probs, pred_time, top_class_description, \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        error_message = f\"<p style='color:red;'>Error during prediction: {str(e)}</p>\"\n",
    "        return {}, \"N/A\", \"N/A\", error_message\n",
    "\n",
    "#######################################\n",
    "# Configure and design the Gradio App #\n",
    "#######################################\n",
    "\n",
    "# Create title, description, and examples\n",
    "title = \"Transform-Eats Large<br>🥪🥗🥣🥩🍝🍣🍰\"\n",
    "description = f\"\"\"\n",
    "A cutting-edge Vision Transformer (ViT) model to classify 101 delicious food types. Discover the power of AI in culinary recognition.\n",
    "\"\"\"\n",
    "\n",
    "# Group food items alphabetically\n",
    "grouped_foods = {letter: [] for letter in string.ascii_uppercase}\n",
    "for food in class_names_102:\n",
    "    first_letter = food[0].upper()  # Get the first letter and make it uppercase\n",
    "    if first_letter in grouped_foods:\n",
    "        grouped_foods[first_letter].append(food)\n",
    "\n",
    "# Function to display food items based on button click\n",
    "def display_foods(letter):\n",
    "    items = grouped_foods.get(letter, [])\n",
    "    return f\"**{letter}:** {', '.join(items)}\" if items else f\"No items for {letter}\"\n",
    "\n",
    "# Configure the Gradio interface\n",
    "with gr.Blocks(theme=\"ocean\") as demo:\n",
    "\n",
    "    # Title and description (at the top)\n",
    "    gr.Markdown(f\"<h1>{title}</h1>\")\n",
    "    gr.Markdown(f\"<p>{description}</p>\")\n",
    "\n",
    "    # Title for supported meals\n",
    "    supported_meals_title = gr.Markdown(\"### Supported Meals\")\n",
    "\n",
    "    # Output display area\n",
    "    output = gr.Markdown()\n",
    "\n",
    "    # Add the supported meals title and buttons in the layout\n",
    "    with gr.Column():\n",
    "\n",
    "        # Keep the title at the top\n",
    "        supported_meals_title  \n",
    "        \n",
    "        with gr.Row():\n",
    "            buttons = []\n",
    "            for letter in string.ascii_uppercase:\n",
    "                button = gr.Button(letter, elem_id=f\"button_{letter}\", size=\"sm\", min_width=40)\n",
    "                button.click(display_foods, inputs=[gr.Textbox(value=letter, visible=False)], outputs=output)\n",
    "                buttons.append(button)\n",
    "\n",
    "    # Configure the upload image area\n",
    "    upload_input = gr.Image(\n",
    "        type=\"pil\",\n",
    "        label=\"Upload Image\",\n",
    "        sources=['upload'],\n",
    "        show_label=True,\n",
    "        mirror_webcam=False\n",
    "    )\n",
    "\n",
    "    model_radio = gr.Radio(\n",
    "        choices=[lite_model, pro_model],\n",
    "        value=pro_model,\n",
    "        label=\"Select the AI algorithm:\",\n",
    "        info=\"ViT Pro is selected by default if none is chosen.\"\n",
    "    )\n",
    "\n",
    "    # Define the status message output field to display error messages\n",
    "    status_output = gr.HTML(label=\"Status:\")\n",
    "\n",
    "    # Set allow flagging\n",
    "    flagging_mode = \"never\"  # \"manual\"\n",
    "\n",
    "    # Author\n",
    "    article = \"Created by Sergio Sanz.\"\n",
    "\n",
    "    # Create the Gradio demo\n",
    "    gr.Interface(\n",
    "        fn=classify_food,                                                  # mapping function from input to outputs\n",
    "        inputs=[upload_input, model_radio],                                # inputs\n",
    "        outputs=[gr.Label(num_top_classes=3, label=\"Prediction\"), \n",
    "                 gr.Textbox(label=\"Prediction time:\"),\n",
    "                 gr.Textbox(label=\"Food Description:\"),\n",
    "                 status_output],                                           # outputs\n",
    "                article=article,                                           # Created by...\n",
    "                flagging_mode=flagging_mode,                               # Only For debugging\n",
    "                flagging_options=[\"correct\", \"incorrect\"],                 # Only For debugging\n",
    "                )  \n",
    "\n",
    "# Launch the demo!\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Creating a Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/requirements.txt\n",
    "torch==2.5.0\n",
    "torchvision==0.20.0\n",
    "gradio==5.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. Copy the Models to the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Copying ..\\models\\effnetb0_2025-01-05_epoch13.pth to ..\\demo\n",
      "[INFO] Copying ..\\models\\effnetb0_2_2025-01-12_epoch13.pth to ..\\demo\n",
      "[INFO] Copying ..\\models\\vitbase16_2_2024-12-31.pth to ..\\demo\n",
      "[INFO] Copying ..\\models\\vitbase16_102_2025-01-04.pth to ..\\demo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\demo\\\\vitbase16_102_2025-01-04.pth'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary classification model: food vs no food\n",
    "source = food_vision_model_path / \"effnetb0_2025-01-05_epoch13.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)\n",
    "\n",
    "# Binary classification model: known vs unknown\n",
    "source = food_vision_model_path / \"effnetb0_2_2025-01-12_epoch13.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)\n",
    "\n",
    "# 101-class classification model\n",
    "source = food_vision_model_path / \"vitbase16_2_2024-12-31.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)\n",
    "\n",
    "# 102-class classification model\n",
    "source = food_vision_model_path / \"vitbase16_102_2025-01-04.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gradio as gr\n",
    "#!cd ../demo\n",
    "#!python ../demo/app.py\n",
    "#gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
