{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will create a proof-on-concept web application that shows the finally selected model in accion. The application will be created using the [Gradio](https://www.gradio.app/) framework and then deployed to HuggingFace to make it publicly available for all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Directories and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FoodVision demo path\n",
    "food_vision_demo_path = Path(\"../demo\")  # Path joining with Path objects\n",
    "food_vision_demo_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make examples directory\n",
    "food_vision_demo_examples_path = food_vision_demo_path / \"examples\"\n",
    "food_vision_demo_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Specify model directory\n",
    "food_vision_model_path = Path(\"../models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Food Description File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON file with the description of th 101 types of food\n",
    "food_descriptions = {\n",
    "    \"apple_pie\": \"A classic American dessert made with spiced apple filling encased in a flaky pastry crust, often served with ice cream.\",\n",
    "    \"baby_back_ribs\": \"Juicy, tender pork ribs, slow-cooked and coated with a flavorful barbecue sauce.\",\n",
    "    \"baklava\": \"A rich, sweet pastry layered with chopped nuts and honey or syrup, originating from the Middle East and Mediterranean regions.\",\n",
    "    \"beef_carpaccio\": \"Thinly sliced raw beef served with olive oil, lemon, capers, and Parmesan, often as a starter.\",\n",
    "    \"beef_tartare\": \"Finely chopped or ground raw beef mixed with seasonings like capers, onions, and egg yolk, served uncooked.\",\n",
    "    \"beet_salad\": \"A refreshing dish featuring cooked or raw beets paired with greens, goat cheese, nuts, and a tangy vinaigrette.\",\n",
    "    \"beignets\": \"Deep-fried dough pastries dusted with powdered sugar, popular in New Orleans as a sweet treat.\",\n",
    "    \"bibimbap\": \"A Korean mixed rice dish topped with vegetables, meat, an egg, and spicy gochujang sauce.\",\n",
    "    \"bread_pudding\": \"A comforting dessert made from bread soaked in a sweet custard mixture and baked until golden.\",\n",
    "    \"breakfast_burrito\": \"A hearty wrap filled with scrambled eggs, cheese, meats, and sometimes vegetables or beans.\",\n",
    "    \"bruschetta\": \"An Italian appetizer of toasted bread rubbed with garlic and topped with fresh tomatoes, olive oil, and basil.\",\n",
    "    \"caesar_salad\": \"A classic salad made with romaine lettuce, croutons, Parmesan cheese, and Caesar dressing.\",\n",
    "    \"cannoli\": \"An Italian dessert consisting of a crispy pastry shell filled with sweet ricotta cheese and sometimes chocolate chips.\",\n",
    "    \"caprese_salad\": \"A simple Italian salad of fresh mozzarella, tomatoes, and basil, drizzled with olive oil and balsamic vinegar.\",\n",
    "    \"carrot_cake\": \"A moist cake made with grated carrots and often topped with cream cheese frosting.\",\n",
    "    \"ceviche\": \"A seafood dish where fresh fish or shrimp is 'cooked' in citrus juice and mixed with onions, peppers, and cilantro.\",\n",
    "    \"cheese_plate\": \"An assortment of cheeses served with accompaniments like crackers, fruit, and nuts.\",\n",
    "    \"cheesecake\": \"A creamy dessert made with a mixture of cream cheese, sugar, and eggs on a graham cracker or pastry crust.\",\n",
    "    \"chicken_curry\": \"A flavorful dish of chicken cooked in a spicy, aromatic curry sauce, popular in South Asian cuisine.\",\n",
    "    \"chicken_quesadilla\": \"A Mexican dish of tortillas filled with cheese, chicken, and spices, grilled until crispy and melty.\",\n",
    "    \"chicken_wings\": \"Juicy chicken wings fried or baked and often coated with a tangy or spicy sauce.\",\n",
    "    \"chocolate_cake\": \"A rich, moist dessert made with layers of chocolate sponge and frosting.\",\n",
    "    \"chocolate_mousse\": \"A light and creamy dessert made with whipped cream and melted chocolate, often served chilled.\",\n",
    "    \"churros\": \"Fried dough pastry, often coated in sugar and cinnamon, typically served with chocolate dipping sauce.\",\n",
    "    \"clam_chowder\": \"A creamy soup made with clams, potatoes, and onions, often served in a bread bowl.\",\n",
    "    \"club_sandwich\": \"A layered sandwich filled with turkey, bacon, lettuce, tomato, and mayonnaise.\",\n",
    "    \"crab_cakes\": \"Pan-fried or baked patties made from lump crab meat and breadcrumbs, seasoned with spices.\",\n",
    "    \"creme_brulee\": \"A custard dessert with a caramelized sugar crust on top, served cold.\",\n",
    "    \"croque_madame\": \"A French grilled sandwich filled with ham and cheese, topped with a fried egg.\",\n",
    "    \"cup_cakes\": \"Small, individual-sized cakes often topped with frosting and decorations.\",\n",
    "    \"deviled_eggs\": \"Hard-boiled eggs halved and filled with a seasoned yolk mixture.\",\n",
    "    \"donuts\": \"Sweet, fried dough pastries, often glazed or topped with sprinkles.\",\n",
    "    \"dumplings\": \"Small dough parcels filled with meat or vegetables, steamed, boiled, or fried.\",\n",
    "    \"edamame\": \"Boiled or steamed young soybeans served in their pods, sprinkled with salt.\",\n",
    "    \"eggs_benedict\": \"A breakfast dish of poached eggs, English muffins, Canadian bacon, and hollandaise sauce.\",\n",
    "    \"escargots\": \"Cooked snails, often served with garlic butter in French cuisine.\",\n",
    "    \"falafel\": \"Deep-fried balls or patties made from ground chickpeas or fava beans, often served in pita bread.\",\n",
    "    \"filet_mignon\": \"A tender and juicy cut of beef steak, often served as a fine dining dish.\",\n",
    "    \"fish_and_chips\": \"A classic British dish of battered and fried fish served with crispy fries.\",\n",
    "    \"foie_gras\": \"A French delicacy made from the liver of a fattened duck or goose, often served as a p√¢t√©.\",\n",
    "    \"french_fries\": \"Thinly sliced potatoes deep-fried until crispy, often served as a side dish.\",\n",
    "    \"french_onion_soup\": \"A hearty soup made with caramelized onions and beef broth, topped with bread and melted cheese.\",\n",
    "    \"french_toast\": \"Bread slices soaked in a milk and egg mixture, fried until golden, and served with syrup.\",\n",
    "    \"fried_calamari\": \"Lightly battered and fried squid rings, often served with marinara or aioli sauce.\",\n",
    "    \"fried_rice\": \"A stir-fried rice dish mixed with vegetables, eggs, and meat or seafood.\",\n",
    "    \"frozen_yogurt\": \"A creamy, tangy dessert similar to ice cream but made with yogurt.\",\n",
    "    \"garlic_bread\": \"Toasted bread slices flavored with garlic butter, often served as a side dish.\",\n",
    "    \"gnocchi\": \"Soft Italian dumplings made from potato, flour, and sometimes cheese, served with sauce.\",\n",
    "    \"greek_salad\": \"A fresh salad made with cucumbers, tomatoes, olives, feta cheese, and olive oil.\",\n",
    "    \"grilled_cheese_sandwich\": \"A hot sandwich filled with melted cheese, grilled until crispy.\",\n",
    "    \"grilled_salmon\": \"Salmon fillets cooked on a grill, often seasoned with herbs and spices.\",\n",
    "    \"guacamole\": \"A creamy dip made from mashed avocados, lime juice, onions, and cilantro.\",\n",
    "    \"gyoza\": \"Japanese dumplings filled with minced meat and vegetables, pan-fried and steamed.\",\n",
    "    \"hamburger\": \"A ground beef patty served in a bun with toppings like lettuce, tomato, and cheese.\",\n",
    "    \"hot_and_sour_soup\": \"A Chinese soup with a tangy and spicy flavor, filled with tofu, mushrooms, and vegetables.\",\n",
    "    \"hot_dog\": \"A grilled or boiled sausage served in a bun with condiments like ketchup and mustard.\",\n",
    "    \"huevos_rancheros\": \"A Mexican breakfast dish with fried eggs, tortillas, and salsa.\",\n",
    "    \"hummus\": \"A creamy dip made from blended chickpeas, tahini, lemon juice, and garlic.\",\n",
    "    \"ice_cream\": \"A frozen dessert made from sweetened cream, often flavored and served in scoops.\",\n",
    "    \"lasagna\": \"An Italian pasta dish layered with meat, cheese, and tomato sauce, baked until bubbly.\",\n",
    "    \"lobster_bisque\": \"A creamy soup made from lobster stock, often served as a gourmet dish.\",\n",
    "    \"lobster_roll_sandwich\": \"A sandwich filled with chunks of lobster meat, dressed in butter or mayo.\",\n",
    "    \"macaroni_and_cheese\": \"A comfort food dish of macaroni pasta mixed with a creamy cheese sauce.\",\n",
    "    \"macarons\": \"Delicate French almond cookies filled with flavored buttercream or ganache.\",\n",
    "    \"miso_soup\": \"A Japanese soup made with fermented soybean paste, tofu, and seaweed.\",\n",
    "    \"mussels\": \"Shellfish steamed and served in a flavorful broth, often with bread.\",\n",
    "    \"nachos\": \"Tortilla chips topped with melted cheese and various toppings like jalape√±os and sour cream.\",\n",
    "    \"omelette\": \"Beaten eggs cooked in a frying pan, often filled with cheese, meats, or vegetables.\",\n",
    "    \"onion_rings\": \"Crispy, deep-fried onion slices, often served as a side dish or snack.\",\n",
    "    \"oysters\": \"Shellfish often served raw on the half shell with lemon or hot sauce.\",\n",
    "    \"pad_thai\": \"Stir-fried rice noodles with eggs, tofu or shrimp, peanuts, and a tamarind-based sauce.\",\n",
    "    \"paella\": \"Spanish rice dish with seafood, meats, and saffron, traditionally cooked in a single pan.\",\n",
    "    \"pancakes\": \"Fluffy round cakes made from flour, eggs, and milk, served with syrup and butter.\",\n",
    "    \"panna_cotta\": \"Italian dessert of sweetened cream thickened with gelatin, often topped with berries or caramel.\",\n",
    "    \"peking_duck\": \"Crispy duck served with pancakes, hoisin sauce, and sliced scallions.\",\n",
    "    \"pho\": \"Vietnamese noodle soup with broth, rice noodles, herbs, and beef or chicken.\",\n",
    "    \"pizza\": \"Flat dough topped with tomato sauce, cheese, and various toppings, baked until crispy.\",\n",
    "    \"pork_chop\": \"Grilled or roasted cut of pork, often served with vegetables or a flavorful sauce.\",\n",
    "    \"poutine\": \"Canadian dish with French fries, cheese curds, and gravy.\",\n",
    "    \"prime_rib\": \"Tender beef rib roast, often seasoned and slow-cooked, served for special occasions.\",\n",
    "    \"pulled_pork_sandwich\": \"Slow-cooked shredded pork with barbecue sauce, served on a bun.\",\n",
    "    \"ramen\": \"Japanese noodle soup with broth, wheat noodles, and toppings like eggs and pork.\",\n",
    "    \"ravioli\": \"Italian dumplings filled with cheese, meat, or vegetables, served with sauce.\",\n",
    "    \"red_velvet_cake\": \"Rich cake with a hint of cocoa and red coloring, layered with cream cheese frosting.\",\n",
    "    \"risotto\": \"Italian creamy rice dish cooked with broth and flavored with vegetables or meat.\",\n",
    "    \"samosa\": \"Deep-fried pastry filled with spiced potatoes, peas, and sometimes meat.\",\n",
    "    \"sashimi\": \"Thinly sliced raw fish or seafood, often served with soy sauce and wasabi.\",\n",
    "    \"scallops\": \"Delicate shellfish, often seared and served as a seafood entr√©e.\",\n",
    "    \"seaweed_salad\": \"Salad made from seasoned edible seaweed, typically with sesame oil and soy sauce.\",\n",
    "    \"shrimp_and_grits\": \"Southern dish of shrimp cooked in a savory sauce, served with creamy grits.\",\n",
    "    \"spaghetti_bolognese\": \"Italian pasta with a rich meat sauce made from ground beef, tomatoes, and herbs.\",\n",
    "    \"spaghetti_carbonara\": \"Pasta with a creamy sauce made from eggs, cheese, pancetta, and black pepper.\",\n",
    "    \"spring_rolls\": \"Rice paper rolls filled with vegetables, meat, or seafood, served with dipping sauce.\",\n",
    "    \"steak\": \"Grilled or pan-seared beef cut, often served with vegetables or potatoes.\",\n",
    "    \"strawberry_shortcake\": \"Dessert with layers of cake, fresh strawberries, and whipped cream.\",\n",
    "    \"sushi\": \"Japanese dish with vinegared rice, raw or cooked seafood, and sometimes vegetables.\",\n",
    "    \"tacos\": \"Mexican dish with a tortilla filled with meat, vegetables, cheese, and salsa.\",\n",
    "    \"takoyaki\": \"Japanese snack made from batter, octopus, and tempura bits, served with takoyaki sauce.\",\n",
    "    \"tiramisu\": \"Italian dessert with coffee-soaked ladyfingers, mascarpone cheese, and cocoa powder.\",\n",
    "    \"tuna_tartare\": \"Finely diced raw tuna, often mixed with soy sauce and served as an appetizer.\",\n",
    "    \"waffles\": \"Batter-based dish cooked in a grid pattern, served with syrup, fruit, or whipped cream.\",\n",
    "    \"unknown\": \"No sufficient confidence to classify the image.\" # \"The current picture is not recognized as one of the 101 food classes. Please try again.\"\n",
    "}\n",
    "\n",
    "food_descriptions = {key.replace(\"_\", \" \"): value for key, value in food_descriptions.items()}\n",
    "\n",
    "# Save to JSON file\n",
    "food_descriptions_json = os.path.join(food_vision_demo_path, 'food_descriptions.json')\n",
    "with open(food_descriptions_json, 'w') as f:\n",
    "    json.dump(food_descriptions, f, indent=4)\n",
    "\n",
    "# Open JSON file\n",
    "# Load the food descriptions from the JSON file\n",
    "with open(food_descriptions_json, 'r') as f:\n",
    "    food_descriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Class Name File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Food-101 class names to ..\\demo\\class_names.txt\n",
      "[INFO] Reading Food-101 class names from ..\\demo\\class_names.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create path to Food-101 class names\n",
    "class_names = list(food_descriptions.keys())\n",
    "food_vision_class_names_path = food_vision_demo_path / \"class_names.txt\"\n",
    "\n",
    "# Write Food-101 class names list to file\n",
    "with open(food_vision_class_names_path, \"w\") as f:\n",
    "    print(f\"[INFO] Saving Food-101 class names to {food_vision_class_names_path}\")\n",
    "    f.write(\"\\n\".join(class_names)) # leave a new line between each class\n",
    "\n",
    "# Open Food-101 class names file\n",
    "with open(food_vision_class_names_path, \"r\") as f:\n",
    "    print(f\"[INFO] Reading Food-101 class names from {food_vision_class_names_path}\")\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    " # Show the first 5 class names\n",
    "class_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Creating Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an examples directory\n",
    "food_vision_examples_path = food_vision_demo_path / \"examples\"\n",
    "food_vision_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect five test image paths\n",
    "food_vision_examples = [Path('../data/food-101_100_percent/test/sushi/511665.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/hot_and_sour_soup/1134579.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/paella/2083247.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/carrot_cake/470617.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/pizza/3770514.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/pork_chop/137031.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/steak/1498778.jpg'),\n",
    "                        Path('../data/food-101_100_percent/test/fried_calamari/936686.jpg')\n",
    "                        ]\n",
    "\n",
    "# Copy the images to the examples directory\n",
    "for example in food_vision_examples:\n",
    "    example_path = food_vision_examples_path / example.name\n",
    "    if not example_path.exists():\n",
    "        print(f\"[INFO] Copying {example} to {example_path}\")\n",
    "        shutil.copy(src=example, dst=example_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Creating the ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/model.py\n",
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from vision_transformer import ViT\n",
    "\n",
    "def load_model(model: torch.nn.Module,\n",
    "               model_weights_dir: str,\n",
    "               model_weights_name: str):\n",
    "\n",
    "    \"\"\"Loads a PyTorch model from a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to load.\n",
    "    model_weights_dir: A directory where the model is located.\n",
    "    model_weights_name: The name of the model to load.\n",
    "      Should include either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    model = load_model(model=model,\n",
    "                       model_weights_dir=\"models\",\n",
    "                       model_weights_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "\n",
    "    Returns:\n",
    "    The loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    # Create the model directory path\n",
    "    model_dir_path = Path(model_weights_dir)\n",
    "\n",
    "    # Create the model path\n",
    "    assert model_weights_name.endswith(\".pth\") or model_weights_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_path = model_dir_path / model_weights_name\n",
    "\n",
    "    # Load the model\n",
    "    print(f\"[INFO] Loading model from: {model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_vitbase_model(\n",
    "    model_weights_dir:Path,\n",
    "    model_weights_name:str,\n",
    "    img_size:int=224,\n",
    "    num_classes:int=101,\n",
    "    compile:bool=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Creates a ViT-B/16 model with the specified number of classes.\n",
    "\n",
    "    Args:\n",
    "        model_weights_dir: A directory where the model is located.\n",
    "        model_weights_name: The name of the model to load.\n",
    "        img_size: The size of the input image.\n",
    "        num_classes: The number of classes for the classification task.\n",
    "\n",
    "    Returns:\n",
    "    The created ViT-B/16 model.\n",
    "    \"\"\"    \n",
    "    # Instantiate the model\n",
    "    vitbase16_model = ViT(\n",
    "        img_size=img_size,\n",
    "        in_channels=3,\n",
    "        patch_size=16,\n",
    "        num_transformer_layers=12,\n",
    "        emb_dim=768,\n",
    "        mlp_size=3072,\n",
    "        num_heads=12,\n",
    "        attn_dropout=0,\n",
    "        mlp_dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # Compile the model\n",
    "    if compile:\n",
    "        vitbase16_model = torch.compile(vitbase16_model, backend=\"aot_eager\")\n",
    "\n",
    "    # Load the trained weights\n",
    "    vitbase16_model = load_model(\n",
    "        model=vitbase16_model,\n",
    "        model_weights_dir=model_weights_dir,\n",
    "        model_weights_name=model_weights_name\n",
    "        )\n",
    "    \n",
    "    return vitbase16_model\n",
    "\n",
    "# Create an EfficientNet-B0 Model\n",
    "def create_effnetb0(\n",
    "        model_weights_dir: Path,\n",
    "        model_weights_name: str,\n",
    "        num_classes: int=2,\n",
    "        dropout: float=0.2\n",
    "        ):\n",
    "    \"\"\"Creates an EfficientNetB0 feature extractor model and transforms.\n",
    "\n",
    "    Args:\n",
    "        model_weights_dir: A directory where the model is located.\n",
    "        model_weights_name: The name of the model to load.\n",
    "        num_classes (int, optional): number of classes in the classifier head.\n",
    "        dropout (float, optional): Dropout rate. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        effnetb0_model (torch.nn.Module): EffNetB0 feature extractor model.\n",
    "        transforms (torchvision.transforms): Image transforms.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights \n",
    "    effnetb0_model = torchvision.models.efficientnet_b0(weights=weights).to('cpu')\n",
    "\n",
    "    # Recreate the classifier layer and seed it to the target device\n",
    "    effnetb0_model.classifier = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=dropout, inplace=True), \n",
    "        torch.nn.Linear(in_features=1280, \n",
    "                        out_features=num_classes,\n",
    "                        bias=True))\n",
    "    \n",
    "    # Create the model directory path\n",
    "    model_dir_path = Path(model_weights_dir)\n",
    "\n",
    "    # Create the model path\n",
    "    assert model_weights_name.endswith(\".pth\") or model_weights_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_path = model_dir_path / model_weights_name\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    effnetb0_model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "        \n",
    "    return effnetb0_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../demo/vision_transformer.py'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy required libraries\n",
    "shutil.copy(src=\"modules/vision_transformer.py\", dst=\"../demo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Creating the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/app.py\n",
    "\n",
    "# Imports and class names setup\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import gradio as gr\n",
    "from model import create_vitbase_model, create_effnetb0\n",
    "from timeit import default_timer as timer\n",
    "from typing import Tuple, Dict\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "# Specify class names\n",
    "food_vision_class_names_path = \"class_names.txt\"\n",
    "with open(food_vision_class_names_path, \"r\") as f:\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    "# Specify number of classes\n",
    "num_classes = len(class_names) - 1 # 101, \"unknown\" to be discarded\n",
    "\n",
    "# Load the food description file\n",
    "food_descriptions_json = \"food_descriptions.json\"\n",
    "with open(food_descriptions_json, 'r') as f:\n",
    "    food_descriptions = json.load(f)\n",
    "\n",
    "# Instantiate the model\n",
    "classification_model_name_path = \"effnetb0_classif_epoch13.pth\"\n",
    "effnetb0_model = create_effnetb0(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=classification_model_name_path,\n",
    "    num_classes=2\n",
    "    )\n",
    "\n",
    "# Load the ViT-Base/16 transformer with input image of 224x224 pixels\n",
    "vitbase_model_1 = create_vitbase_model(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=\"vitbase16_5.pth\",\n",
    "    img_size=224,\n",
    "    num_classes=num_classes,\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Specify manual transforms for model_1\n",
    "transforms_1 = v2.Compose([    \n",
    "    v2.Resize((242, 242)),\n",
    "    v2.CenterCrop((224, 224)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Load the ViT-Base/16 transformer with input image of 384x384 pixels \n",
    "vitbase_model_2 = create_vitbase_model(\n",
    "    model_weights_dir=\".\",\n",
    "    model_weights_name=\"vitbase16_2_2024-12-31.pth\",\n",
    "    img_size=384,\n",
    "    num_classes=num_classes,\n",
    "    compile=True\n",
    ")\n",
    "\n",
    "# Specify manual transforms for model_2\n",
    "transforms_2 = v2.Compose([    \n",
    "    v2.Resize(384), #v2.Resize((384, 384)),\n",
    "    v2.CenterCrop((384, 384)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Put models into evaluation mode and turn on inference mode\n",
    "effnetb0_model.eval()\n",
    "vitbase_model_1.eval()\n",
    "vitbase_model_2.eval()\n",
    "\n",
    "# Specify default ViT model\n",
    "default_model = \"Vision Transformer - 384x384 pixels (higher accuracy, slower predictions)\" # \"Vision Transformer - 224x224 pixels (lower accuracy, faster predictions)\"\n",
    "\n",
    "# Predict function\n",
    "def predict(image) -> Tuple[Dict, str, str]:\n",
    "\n",
    "    \"\"\"Transforms and performs a prediction on image and returns prediction and time taken.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Start the timer\n",
    "        start_time = timer()\n",
    "\n",
    "        # Select the appropriate model based on the user's choice\n",
    "        if default_model == \"Vision Transformer - 384x384 pixels (higher accuracy, slower predictions)\":\n",
    "            vitbase_model = vitbase_model_2\n",
    "            transforms = transforms_2\n",
    "        else:\n",
    "            vitbase_model = vitbase_model_1\n",
    "            transforms = transforms_1\n",
    "        \n",
    "        # Transform the target image and add a batch dimension\n",
    "        image = transforms(image).unsqueeze(0)\n",
    "        \n",
    "        # Make prediction...\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            # If the picture is food\n",
    "            if effnetb0_model(image)[:,1].cpu() >= 0.9981166124343872:\n",
    "\n",
    "                # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
    "                pred_probs = torch.softmax(vitbase_model(image), dim=1) # 101 classes\n",
    "\n",
    "                # Calculate entropy\n",
    "                entropy = -torch.sum(pred_probs * torch.log(pred_probs), dim=1).item()\n",
    "\n",
    "                # Create a prediction label and prediction probability dictionary for each prediction class\n",
    "                pred_classes_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(num_classes)}\n",
    "                pred_classes_and_probs[\"unknown\"] = 0.0\n",
    "\n",
    "                # Get the top predicted class\n",
    "                top_class = max(pred_classes_and_probs, key=pred_classes_and_probs.get)\n",
    "\n",
    "                # If the image is likely to be an unknown category\n",
    "                if pred_probs[0][class_names.index(top_class)] <= 0.5 and entropy > 2.6:\n",
    "\n",
    "                    # Create prediction label and prediction probability for class unknown and rescale the rest of predictions\n",
    "                    pred_classes_and_probs[\"unknown\"] = pred_probs.max() * 1.25\n",
    "                    prob_sum = sum(pred_classes_and_probs.values())\n",
    "                    pred_classes_and_probs = {key: value / prob_sum for key, value in pred_classes_and_probs.items()}\n",
    "\n",
    "                    # Get the top predicted class\n",
    "                    top_class = \"unknown\"\n",
    "\n",
    "            # Otherwise\n",
    "            else:\n",
    "\n",
    "                # Set all probabilites to zero except class unknown\n",
    "                pred_classes_and_probs = {class_names[i]: 0.0 for i in range(num_classes)}\n",
    "                pred_classes_and_probs[\"unknown\"] = 1.0\n",
    "            \n",
    "                # Get the top predicted class\n",
    "                top_class = \"unknown\"\n",
    "        \n",
    "        # Get the description of the top predicted class\n",
    "        top_class_description = food_descriptions.get(top_class, \"Description not available.\")\n",
    "\n",
    "        # Calculate the prediction time\n",
    "        pred_time = f\"{round(timer() - start_time, 1)} s.\"\n",
    "        \n",
    "        # Return the prediction dictionary and prediction time \n",
    "        return pred_classes_and_probs, pred_time, top_class_description\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return {}, \"Error during prediction.\", \"N/A\"\n",
    "\n",
    "# Configure and design the Gradio App\n",
    "\n",
    "# Create title, description, and examples\n",
    "title = \"Transform-Eats Large<br>ü•™ü•óü•£ü•©üçùüç£üç∞\"\n",
    "description = f\"\"\"\n",
    "A cutting-edge Vision Transformer (ViT) model to classify 101 delicious food types. Discover the power of AI in culinary recognition.\n",
    "\n",
    "### Supported Food Types\n",
    "{', '.join(class_names[:-1])}.\n",
    "\"\"\"\n",
    "\n",
    "# Configure the upload image area\n",
    "upload_input = gr.Image(type=\"pil\", label=\"Upload Image\", sources=['upload'], show_label=True, mirror_webcam=False)\n",
    "\n",
    "# Configure the dropdown option\n",
    "#model_dropdown = gr.Dropdown(\n",
    "#    choices=[\"Vision Transformer - 384x384 pixels (higher accuracy, slower predictions)\",\n",
    "#             \"Vision Transformer - 224x224 pixels (lower accuracy, faster predictions)\"],\n",
    "#    value=\"Vision Transformer - 384x384 pixels (higher accuracy, slower predictions)\",\n",
    "#    label=\"Select Model:\"\n",
    "#)\n",
    "\n",
    "# Configure the sample image area\n",
    "food_vision_examples = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
    "\n",
    "# Author\n",
    "article = \"Created by Sergio Sanz.\"\n",
    "\n",
    "# Create sliders for the thresholds\n",
    "#prob = gr.Slider(minimum=0, maximum=1, step=0.05, value=0.4, label=\"Probability Threshold\")\n",
    "#entropy = gr.Slider(minimum=0, maximum=4.615, step=0.5, value=2.5, label=\"Entropy Threshold\")\n",
    "\n",
    "# Create the Gradio demo\n",
    "demo = gr.Interface(fn=predict,                                                # mapping function from input to outputs\n",
    "                    inputs=upload_input,                                       # inputs #[upload_input, model_dropdown]\n",
    "                    outputs=[gr.Label(num_top_classes=3, label=\"Prediction\"), \n",
    "                             gr.Textbox(label=\"Prediction time:\"),\n",
    "                             gr.Textbox(label=\"Food Description:\")],           # outputs\n",
    "                    examples=food_vision_examples,                             # Create examples list from \"examples/\" directory\n",
    "                    cache_examples=True,                                       # Cache the examples\n",
    "                    title=title,                                               # Title of the app\n",
    "                    description=description,                                   # Brief description of the app\n",
    "                    article=article,                                           # Created by...\n",
    "                    theme=\"ocean\")                                             # Theme\n",
    "\n",
    "# Launch the demo!\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Creating a Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../demo/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../demo/requirements.txt\n",
    "torch==2.5.0\n",
    "torchvision==0.20.0\n",
    "gradio==5.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. Copy the Models to the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Copying ..\\models\\effnetb0_classif_epoch13.pth to ..\\demo\n",
      "[INFO] Copying ..\\models\\vitbase16_5.pth to ..\\demo\n",
      "[INFO] Copying ..\\models\\vitbase16_2_2024-12-31.pth to ..\\demo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\demo\\\\vitbase16_2_2024-12-31.pth'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary classification model: food vs no food\n",
    "source = food_vision_model_path / \"effnetb0_classif_epoch13.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)\n",
    "\n",
    "# 101-class classification model 1\n",
    "source = food_vision_model_path / \"vitbase16_5.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)\n",
    "\n",
    "# 101-class classification model 2\n",
    "source = food_vision_model_path / \"vitbase16_2_2024-12-31.pth\"\n",
    "destination = food_vision_demo_path\n",
    "print(f\"[INFO] Copying {source} to {destination}\")\n",
    "shutil.copy(src=source, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.themes.builder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
